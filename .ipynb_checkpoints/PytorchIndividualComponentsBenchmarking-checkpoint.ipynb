{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/castor/seas_home/a/akaush/aurora3env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from aurora import AuroraSmall\n",
    "from aurora.batch import Batch\n",
    "from aurora.model.encoder import Perceiver3DEncoder\n",
    "from aurora.model.swin3d import Swin3DTransformerBackbone\n",
    "from aurora.model.decoder import Perceiver3DDecoder\n",
    "from aurora.model.encoder import Perceiver3DEncoder\n",
    "from aurora.model.swin3d import Swin3DTransformerBackbone\n",
    "from aurora.model.decoder import Perceiver3DDecoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AuroraSmall(use_lora=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\"Aurora\" object has no attribute \"load_checkpoint\". If \"load_checkpoint\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model = AuroraSmall(use_lora=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_checkpoint\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mmicrosoft/aurora\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maurora-0.25-small-pretrained.ckpt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m model.eval()\n\u001b[32m      4\u001b[39m model = model.to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/castor/seas_home/a/akaush/aurora3env/lib/python3.12/site-packages/flax/linen/module.py:1314\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1310\u001b[39m   msg += (\n\u001b[32m   1311\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m If \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m is defined in \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m.setup()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m, remember these fields \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1312\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mare only accessible from inside \u001b[39m\u001b[33m'\u001b[39m\u001b[33minit\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1313\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[31mAttributeError\u001b[39m: \"Aurora\" object has no attribute \"load_checkpoint\". If \"load_checkpoint\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'."
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-small-pretrained.ckpt\")\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "i = 1  # Select this time index in the downloaded data.\n",
    "\n",
    "batch = Batch(\n",
    "    surf_vars={\n",
    "        # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "        # batch dimension of size one.\n",
    "        \"2t\": jnp.array(surf_vars_ds[\"t2m\"].values[[i - 1, i]][None]),\n",
    "        \"10u\": jnp.array(surf_vars_ds[\"u10\"].values[[i - 1, i]][None]),\n",
    "        \"10v\": jnp.array(surf_vars_ds[\"v10\"].values[[i - 1, i]][None]),\n",
    "        \"msl\": jnp.array(surf_vars_ds[\"msl\"].values[[i - 1, i]][None]),\n",
    "    },\n",
    "    static_vars={\n",
    "        # The static variables are constant, so we just get them for the first time.\n",
    "        \"z\": jnp.array(static_vars_ds[\"z\"].values[0]),\n",
    "        \"slt\": jnp.array(static_vars_ds[\"slt\"].values[0]),\n",
    "        \"lsm\": jnp.array(static_vars_ds[\"lsm\"].values[0]),\n",
    "    },\n",
    "    atmos_vars={\n",
    "        \"t\": jnp.array(atmos_vars_ds[\"t\"].values[[i - 1, i]][None]),\n",
    "        \"u\": jnp.array(atmos_vars_ds[\"u\"].values[[i - 1, i]][None]),\n",
    "        \"v\": jnp.array(atmos_vars_ds[\"v\"].values[[i - 1, i]][None]),\n",
    "        \"q\": jnp.array(atmos_vars_ds[\"q\"].values[[i - 1, i]][None]),\n",
    "        \"z\": jnp.array(atmos_vars_ds[\"z\"].values[[i - 1, i]][None]),\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        lat=jnp.array(surf_vars_ds.latitude.values, dtype=jnp.float32),\n",
    "        lon=jnp.array(surf_vars_ds.longitude.values, dtype=jnp.float32),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(\n",
    "            jnp.array(\n",
    "                surf_vars_ds.valid_time.values.astype(\"datetime64[s]\").tolist()[1].timestamp(),\n",
    "                dtype=jnp.int64,\n",
    "            ),\n",
    "        ),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.pressure_level.values),\n",
    "    ),\n",
    ")\n",
    "\n",
    "H, W = batch.spatial_shape\n",
    "patch_res   = (\n",
    "    model.encoder.latent_levels,\n",
    "    H // model.patch_size,\n",
    "    W // model.patch_size,\n",
    ")\n",
    "rollout_step = batch.metadata.rollout_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_encoder(model, batch, n_warmup=1, n_runs=20):\n",
    "    # warm-up\n",
    "    for _ in range(n_warmup):\n",
    "        _ = model.encoder(batch, lead_time=model.timestep)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # timed\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model.encoder(batch, lead_time=model.timestep)\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.perf_counter()\n",
    "        times.append((t1 - t0) * 1000.0)\n",
    "    arr = np.array(times)\n",
    "    print(f\"Encoder: mean {arr.mean():.2f} ms ± {arr.std():.2f} ms over {n_runs} runs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_backbone(model, x, patch_res, rollout_step, n_warmup=1, n_runs=20):\n",
    "    # warm-up\n",
    "    for _ in range(n_warmup):\n",
    "        _ = model.backbone(\n",
    "            x, lead_time=model.timestep, patch_res=patch_res, rollout_step=rollout_step\n",
    "        )\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # timed\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model.backbone(\n",
    "            x, lead_time=model.timestep, patch_res=patch_res, rollout_step=rollout_step\n",
    "        )\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.perf_counter()\n",
    "        times.append((t1 - t0) * 1000.0)\n",
    "    arr = np.array(times)\n",
    "    print(f\"Backbone: mean {arr.mean():.2f} ms ± {arr.std():.2f} ms over {n_runs} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_decoder(model, x, batch, patch_res, n_warmup=1, n_runs=20):\n",
    "    # warm-up\n",
    "    for _ in range(n_warmup):\n",
    "        _ = model.decoder(\n",
    "            x, batch, lead_time=model.timestep, patch_res=patch_res\n",
    "        )\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # timed\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model.decoder(\n",
    "            x, batch, lead_time=model.timestep, patch_res=patch_res\n",
    "        )\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.perf_counter()\n",
    "        times.append((t1 - t0) * 1000.0)\n",
    "    arr = np.array(times)\n",
    "    print(f\"Decoder: mean {arr.mean():.2f} ms ± {arr.std():.2f} ms over {n_runs} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_encoder(model, batch, n_warmup=1, n_runs=20)\n",
    "x_enc = model.encoder(batch, lead_time=model.timestep)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 2) Backbone → x_back\n",
    "benchmark_backbone(model, x_enc, patch_res, rollout_step, n_warmup=1, n_runs=20)\n",
    "x_back = model.backbone(\n",
    "    x_enc,\n",
    "    lead_time=model.timestep,\n",
    "    patch_res=patch_res,\n",
    "    rollout_step=rollout_step,\n",
    ")\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 3) Decoder\n",
    "benchmark_decoder(model, x_back, batch, patch_res, n_warmup=1, n_runs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aurora3env)",
   "language": "python",
   "name": "aurora3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
